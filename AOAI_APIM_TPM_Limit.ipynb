{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API-M's AI Gateway: Azure OpenAI token limit\n",
    "\n",
    "This notebook explores the enforcemnt of a custom token-per-minute (TPM) quota per app or user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required packages\n",
    "from openai import AzureOpenAI\n",
    "import requests\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting environment variables\n",
    "APIM_TPM_URL = os.getenv(\"APIM_TPM_URL\")\n",
    "APIM_TPM_SUB_KEY = os.getenv(\"APIM_TPM_SUB_KEY\")\n",
    "AOAI_API_VERSION = os.getenv(\"APIM_TPM_API_VERSION\")\n",
    "AOAI_DEPLOYMENT = os.getenv(\"APIM_TPM_AOAI_DEPLOY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining custom variables\n",
    "SYSTEM_PROMPT = \"You are a standup comedian.\"\n",
    "USER_PROMPT = \"Tell me a joke about red panda.\"\n",
    "NUMBER_OF_RUNS = 5\n",
    "SLEEP_TIME = 15\n",
    "TEMPERATURE = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing API-M endpoint with REST request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for REST API call\n",
    "def get_rest_completion(system_prompt, user_prompt):\n",
    "    response = requests.post(\n",
    "        url = f\"{APIM_TPM_URL}openai/deployments/{AOAI_DEPLOYMENT}/chat/completions\",\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"api-key\": APIM_TPM_SUB_KEY\n",
    "        },\n",
    "        params={'api-version': AOAI_API_VERSION},\n",
    "        json = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                   \"role\": \"system\",\n",
    "                    \"content\": system_prompt\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_prompt\n",
    "                }\n",
    "            ],\n",
    "        \"temperature\": TEMPERATURE\n",
    "        }\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 0 completed in 0.96 seconds\n",
      "Consumed tokens: 54\n",
      "Remaining tokens: 46\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 1 completed in 0.74 seconds\n",
      "Consumed tokens: 59\n",
      "Remaining tokens: 0\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 2 completed in 0.24 seconds\n",
      "Response code: 429\n",
      "Response message: Token limit is exceeded. Try again in 29 seconds.\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 3 completed in 0.23 seconds\n",
      "Response code: 429\n",
      "Response message: Token limit is exceeded. Try again in 14 seconds.\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 4 completed in 0.73 seconds\n",
      "Consumed tokens: 54\n",
      "Remaining tokens: 0\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing REST API\n",
    "for i in range(NUMBER_OF_RUNS):\n",
    "    start_time = time.time()\n",
    "    response = get_rest_completion(SYSTEM_PROMPT, USER_PROMPT)\n",
    "    end_time = time.time()\n",
    "    print(f\"Run # {i} completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    if response.status_code == 200:        \n",
    "        print(f\"Consumed tokens: {response.headers['consumed-tokens']}\")\n",
    "        print(f\"Remaining tokens: {response.headers['remaining-tokens']}\")    \n",
    "    else:\n",
    "        print(f\"Response code: {response.status_code}\")\n",
    "        print(f\"Response message: {response.json().get('message')}\")        \n",
    "    \n",
    "    if i < NUMBER_OF_RUNS - 1:\n",
    "        print(f\"Pausing for {SLEEP_TIME} seconds...\")\n",
    "        time.sleep(SLEEP_TIME)\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing API-M endpoint with OpenAI SDK v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = APIM_TPM_URL,\n",
    "    api_key = APIM_TPM_SUB_KEY,\n",
    "    api_version = AOAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for SDK call\n",
    "def get_sdk_completion(system_prompt, prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    response = client.chat.completions.with_raw_response.create(\n",
    "        model = AOAI_DEPLOYMENT,\n",
    "        messages = messages,\n",
    "        temperature = TEMPERATURE\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<APIResponse [200 OK] type=<class 'openai.types.chat.chat_completion.ChatCompletion'>>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = get_sdk_completion(SYSTEM_PROMPT, USER_PROMPT)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run # 0 completed in 45.82 seconds\n",
      "Consumed tokens: 55\n",
      "Remaining tokens: 0\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 1 completed in 0.65 seconds\n",
      "Consumed tokens: 55\n",
      "Remaining tokens: 0\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 2 completed in 30.87 seconds\n",
      "Consumed tokens: 55\n",
      "Remaining tokens: 0\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 3 completed in 1.20 seconds\n",
      "Consumed tokens: 63\n",
      "Remaining tokens: 0\n",
      "Pausing for 15 seconds...\n",
      "-----------------------------\n",
      "Run # 4 completed in 29.88 seconds\n",
      "Consumed tokens: 56\n",
      "Remaining tokens: 0\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing SDK\n",
    "for i in range(NUMBER_OF_RUNS):\n",
    "    start_time = time.time()\n",
    "    response = get_sdk_completion(SYSTEM_PROMPT, USER_PROMPT)\n",
    "    end_time = time.time()\n",
    "    print(f\"Run # {i} completed in {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    if response.http_response.status_code == 200:        \n",
    "        print(f\"Consumed tokens: {response.headers['consumed-tokens']}\")\n",
    "        print(f\"Remaining tokens: {response.headers['remaining-tokens']}\")    \n",
    "    else:\n",
    "        print(f\"Response code: {response.http_response.status_code}\")\n",
    "        print(f\"Response message: {response.http_response.reason_phrase}\")  \n",
    "\n",
    "    if i < NUMBER_OF_RUNS - 1:\n",
    "        print(f\"Pausing for {SLEEP_TIME} seconds...\")\n",
    "        time.sleep(SLEEP_TIME)\n",
    "    print(\"-----------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
